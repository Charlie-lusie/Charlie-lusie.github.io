---
title: '[CVPR 2020] Joint 3D Instance Segmentation and Object Detection for Autonomous Driving'
date: 20120-07-14
permalink: /posts/2020/07/blog-post-1/
tags:
  - Detection
  - LiDAR
  - Paper Reading
---
这篇文章的思路是讲分割与检测结合起来，用分割来提升检测的精度，并且能免除掉NMS等操作；

贡献
------

- 提出spatial embedding（SE）特征，使用到了bbox信息和点特征
- 提出一个统一的网络框架来同时完成检测和实例分割

做法
------

第一阶段网络：首先使用一个backbone提取点级别特征，比如PointNet++，然后分为语义分割和实例相关SE两支。在SE的结果基础上，使用一个聚类层来产生实例分割结果并且生成对应的bbox proposal。

然后是第二阶段的网络，用一个refine网络对上面产生的proposal进行细化调整。

从第一阶段说起。
- 点特征提取用的是pointnet++，当然也可以换别的，但我觉得目前就pn++比较好，能兼顾局部和全局特征。
- 语义分割所需要的信息就来自上面pn++提取到的合并特征，并且为了应对类间不平衡，使用了focal loss：
$$
L_{cls} = -\Sum_{i=1}^C (y_i\log (p_i))(1-p_i)^\gamma \alpha_i + (1- y_i)\log (1-p_i) p_i^\gamma (1 - \alpha_i))
$$
其中C是类的数量，yi=1，如果真值为第i类，否则为0；pi就是预测的第i类的得分。
- 2
